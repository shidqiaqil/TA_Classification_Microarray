{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0      1      2      3        4      5      6      7      8      9      \\\n",
      "0  -161.8   34.8  -34.4  179.1   4796.7     12   19.3  -51.6   21.4 -135.8   \n",
      "1  -231.0 -102.0  -31.0   61.0   8931.0    -33  164.0   -6.0  -34.0 -215.0   \n",
      "2  -279.0   91.0  -30.0  148.0  13966.0     23  287.0 -114.0   90.0  -52.0   \n",
      "3   -20.0  115.0  -10.0   29.0  12994.0     29  304.0  -73.0  -27.0 -126.0   \n",
      "4  -268.0  128.0   80.0  337.0  10895.0    246  204.0 -311.0    0.0 -286.0   \n",
      "5  -370.0   10.0   22.0  153.0  15493.0    119  338.0   -6.0   77.0 -390.0   \n",
      "6   -50.0   30.0   35.0   14.0  11677.0     16  236.0  -32.0   65.0 -123.0   \n",
      "7  -455.0  -91.0   12.0   76.0  13701.0     37  164.0 -105.0  -12.0 -258.0   \n",
      "8  -105.0   12.0   18.0   81.0  21914.0    156  296.0  -10.0   50.0 -274.0   \n",
      "9  -377.0  270.0   52.0  195.0  13842.0    138  245.0    5.0  -29.0 -190.0   \n",
      "10 -479.0  187.0   41.0  191.0   3998.0    138  305.0  -69.0   60.0 -405.0   \n",
      "11 -182.0   44.0   75.0  311.0  16362.0     18  283.0  -83.0   -4.0  -14.0   \n",
      "12  -46.0  104.0   45.0  313.0  14914.0    190  467.0  -94.0   12.0 -440.0   \n",
      "13 -224.0   24.0   17.0  189.0  12325.0     98  402.0  -91.0    8.0 -178.0   \n",
      "14   66.0    0.0   39.0  181.0  17368.0    132  145.0   -6.0   55.0   85.0   \n",
      "15 -305.0 -146.0   50.0   13.0  17219.0    -37  235.0  -59.0   24.0   27.0   \n",
      "16 -350.0 -169.0   29.0   91.0  12939.0    -61  260.0 -241.0   14.0    1.0   \n",
      "17 -211.0   42.0   25.0   48.0  17572.0     22  260.0    2.0  -28.0 -165.0   \n",
      "18 -409.0   52.0   50.0  144.0  12989.0     77  279.0  -28.0  -34.0 -324.0   \n",
      "19 -170.0  -98.0  -48.0  445.0  11605.0     77  430.0 -111.0  106.0  -40.0   \n",
      "37 -336.0  -49.0    4.0  619.0  18422.0    226  161.0 -376.0   76.0 -436.0   \n",
      "38 -288.0 -106.0  135.0  301.0  25897.0     26  261.0   82.0   14.0 -286.0   \n",
      "39 -195.0   71.0   82.0  367.0  13051.0     66  495.0  -61.0    7.0 -592.0   \n",
      "40   16.0  160.0   -5.0  445.0  30348.0    137  484.0  -72.0   -2.0 -363.0   \n",
      "41 -166.0   -1.0  120.0  307.0  25025.0     24  330.0   -5.0   59.0 -256.0   \n",
      "42   36.0    7.0    2.0  217.0  20771.0     -5  219.0  -77.0   -8.0 -163.0   \n",
      "43 -308.0  401.0  101.0   64.0  23002.0    -23  250.0  -46.0    1.0 -322.0   \n",
      "44  147.0   43.0   -2.0  202.0  37354.0     50  178.0 -100.0  -12.0 -228.0   \n",
      "45  -56.0  102.0   83.0  245.0  19576.0     49  243.0  -89.0   76.0 -294.0   \n",
      "46 -522.0  119.0   30.0  489.0  12817.0    192  634.0 -132.0  -18.0  -81.0   \n",
      "47 -115.0    9.0  102.0  374.0  28131.0    132  321.0  -81.0  -25.0  -39.0   \n",
      "48 -231.0   74.0  -15.0  681.0  13201.0    117  567.0 -153.0   35.0 -386.0   \n",
      "49 -196.0   -3.0 -154.0  183.0  15404.0    266  465.0 -265.0   84.0 -435.0   \n",
      "50 -189.0  102.0   25.0  406.0  20865.0     99  273.0 -242.0 -167.0 -532.0   \n",
      "51  -69.0    6.0  146.0  438.0  26238.0    169  697.0 -242.0   70.0 -506.0   \n",
      "52 -455.0  201.0   17.0  171.0  18003.0    181  386.0 -179.0  112.0 -245.0   \n",
      "53 -146.0  144.0   63.0  380.0  21192.0    152  691.0 -394.0  -35.0 -457.0   \n",
      "54 -196.0  205.0   58.0  167.0  15538.0     28  357.0  -48.0    0.0 -173.0   \n",
      "55 -184.0  103.0   35.0   33.0  19247.0    204  638.0 -617.0  -19.0 -499.0   \n",
      "56  -71.0    6.0  122.0  270.0  19983.0     38  514.0 -246.0   66.0 -466.0   \n",
      "0  -163.0 -199.0   -7.0   69.0  10327.0     58  217.0 -308.0  110.0 -262.0   \n",
      "1  -310.0   19.0    0.0   48.0   1453.0     60  252.0    1.0  -42.0   11.0   \n",
      "2  -216.0  126.0  -35.0   66.0  12334.0     48  230.0  -73.0   12.0 -161.0   \n",
      "3  -130.0  225.0   64.0  110.0  16464.0     48  254.0   24.0  -64.0    2.0   \n",
      "7   -53.0   -7.0    4.0  213.0  27616.0     81  398.0   -5.0   18.0 -253.0   \n",
      "8   -67.0  -90.0   18.0  396.0  20052.0    140  577.0 -163.0 -119.0 -576.0   \n",
      "9  -100.0  167.0   58.0  198.0  11788.0     65  452.0 -123.0   55.0 -375.0   \n",
      "10 -169.0  142.0   19.0  282.0  18765.0    138  339.0 -232.0   71.0 -648.0   \n",
      "11 -490.0   44.0 -114.0   60.0  18552.0     50  324.0   63.0   44.0 -203.0   \n",
      "12  -17.0   42.0    9.0  492.0  14277.0    206  674.0 -171.0  -26.0 -704.0   \n",
      "13 -138.0  207.0  113.0  446.0  25971.0     43  458.0  -46.0   24.0  -52.0   \n",
      "14 -109.0  166.0   28.0  541.0  29595.0     90  643.0 -167.0   12.0 -335.0   \n",
      "\n",
      "    ...     12573  12574   12575   12576  12577   12578   12579   12580  \\\n",
      "0   ...    -225.2  242.5   101.7   473.1  -59.9   217.9   275.6  -461.6   \n",
      "1   ...    -175.0  143.0    96.0   301.0  -50.0   242.0   222.0  -330.0   \n",
      "2   ...    -308.0  184.0   -32.0   350.0  -11.0   837.0   174.0   -99.0   \n",
      "3   ...     731.0  106.0  -330.0   -36.0 -190.0   999.0   255.0  -353.0   \n",
      "4   ...     182.0  426.0   155.0   607.0   50.0   249.0  1635.0  -780.0   \n",
      "5   ...    -207.0  205.0    31.0   377.0   76.0   337.0  -260.0  -921.0   \n",
      "6   ...    -226.0   67.0   101.0   332.0   49.0   195.0   526.0  -433.0   \n",
      "7   ...      20.0  219.0   232.0   425.0 -144.0   710.0    61.0 -1194.0   \n",
      "8   ...    -108.0   80.0   574.0   452.0  -37.0   372.0  -520.0 -1073.0   \n",
      "9   ...    -129.0   86.0   151.0   538.0   87.0   412.0  1230.0 -1066.0   \n",
      "10  ...    -149.0   74.0    39.0   623.0  -81.0   488.0   538.0  -842.0   \n",
      "11  ...     609.0  152.0    10.0   197.0   48.0  1280.0   281.0  -476.0   \n",
      "12  ...     521.0  140.0    53.0   455.0  -29.0  1355.0   523.0 -1466.0   \n",
      "13  ...     404.0  102.0   204.0   601.0  110.0  2022.0   614.0  -759.0   \n",
      "14  ...    -340.0   51.0   158.0   409.0  -68.0    35.0    76.0 -1078.0   \n",
      "15  ...    1010.0  159.0  -190.0   278.0  -16.0  1190.0   132.0  -244.0   \n",
      "16  ...      16.0   68.0  -124.0   367.0 -129.0   618.0  1252.0  -200.0   \n",
      "17  ...     513.0  104.0    92.0   184.0   54.0   941.0   232.0  -280.0   \n",
      "18  ...     944.0  142.0    44.0   412.0   34.0   620.0  -151.0  -474.0   \n",
      "19  ...     146.0  459.0   148.0   683.0 -110.0   275.0   818.0 -1160.0   \n",
      "37  ...    -535.0  316.0    87.0   680.0  157.0  2498.0   678.0 -1305.0   \n",
      "38  ...    -331.0  191.0   819.0   317.0   11.0   884.0   128.0  -504.0   \n",
      "39  ...    -501.0  310.0  1212.0   605.0    5.0  4906.0   841.0  -973.0   \n",
      "40  ...    -102.0  -15.0   -61.0   526.0 -122.0   441.0   -78.0 -1045.0   \n",
      "41  ...    -342.0  158.0  -179.0   440.0 -313.0  1583.0   -54.0 -1485.0   \n",
      "42  ...    -502.0  207.0     5.0   538.0 -146.0  7567.0   127.0 -1564.0   \n",
      "43  ...    -386.0   98.0   146.0   650.0   83.0   462.0  -326.0 -1799.0   \n",
      "44  ...     152.0  108.0   214.0   192.0  121.0   207.0  -122.0  -446.0   \n",
      "45  ...     149.0  189.0    22.0   493.0  -66.0   528.0   -18.0  -673.0   \n",
      "46  ...    -303.0  237.0    28.0  1078.0  156.0  1168.0  -598.0 -1020.0   \n",
      "47  ...    -402.0   59.0    26.0   836.0  215.0   108.0    31.0  -646.0   \n",
      "48  ...    -522.0  306.0   322.0   379.0  144.0  2314.0    11.0   -18.0   \n",
      "49  ...    -566.0  446.0    65.0   162.0 -260.0  2663.0   646.0 -1769.0   \n",
      "50  ...    -293.0  396.0   433.0   560.0  -45.0   232.0   174.0 -1293.0   \n",
      "51  ...    -750.0  261.0  -234.0   722.0   47.0   571.0   569.0 -1985.0   \n",
      "52  ...    -577.0  389.0  -105.0   980.0    7.0  1802.0   944.0 -1415.0   \n",
      "53  ...    -527.0   79.0  -188.0   960.0   -8.0  5559.0  -167.0 -3352.0   \n",
      "54  ...     126.0  505.0     5.0   364.0    1.0  1334.0   190.0  -725.0   \n",
      "55  ...    -935.0  420.0    27.0  1101.0   78.0  1407.0   736.0 -3042.0   \n",
      "56  ...    -444.0  220.0   127.0   838.0   41.0   559.0  2512.0 -2107.0   \n",
      "0   ...     236.0  241.0    29.0   378.0  -25.0   167.0  1380.0  -509.0   \n",
      "1   ...    -134.0  219.0   406.0   494.0  -32.0  1359.0   -84.0  -348.0   \n",
      "2   ...    -158.0  136.0   128.0   588.0  -86.0   537.0  1042.0  -941.0   \n",
      "3   ...     350.0  128.0    82.0   212.0   43.0    94.0    67.0  -350.0   \n",
      "7   ...     280.0   40.0    37.0   327.0  101.0   508.0   266.0  -887.0   \n",
      "8   ...    -422.0  254.0   366.0   910.0  124.0  1538.0  1194.0 -1638.0   \n",
      "9   ...    -454.0  428.0   258.0   856.0  -26.0  3554.0   162.0 -1278.0   \n",
      "10  ...    -422.0  528.0   220.0   643.0  187.0   407.0  -564.0 -1736.0   \n",
      "11  ...     128.0   94.0    66.0   556.0   63.0   200.0   120.0  -757.0   \n",
      "12  ...    -230.0  257.0    71.0   581.0   64.0    35.0   829.0 -2015.0   \n",
      "13  ...    -236.0   88.0    94.0   143.0  232.0   434.0   -87.0 -2038.0   \n",
      "14  ...    -625.0  139.0     7.0   718.0  230.0   743.0  -313.0 -1770.0   \n",
      "\n",
      "     12581  12582  \n",
      "0   1115.5    ALL  \n",
      "1   2481.0    ALL  \n",
      "2    376.0    ALL  \n",
      "3   1603.0    ALL  \n",
      "4   1103.0    ALL  \n",
      "5    801.0    ALL  \n",
      "6    806.0    ALL  \n",
      "7   1285.0    ALL  \n",
      "8   1222.0    ALL  \n",
      "9   2926.0    ALL  \n",
      "10  1263.0    ALL  \n",
      "11  1174.0    ALL  \n",
      "12   817.0    ALL  \n",
      "13  1417.0    ALL  \n",
      "14  1539.0    ALL  \n",
      "15  2369.0    ALL  \n",
      "16  1990.0    ALL  \n",
      "17  1703.0    ALL  \n",
      "18  1826.0    ALL  \n",
      "19   739.0    ALL  \n",
      "37  1027.0    AML  \n",
      "38   618.0    AML  \n",
      "39  1030.0    AML  \n",
      "40   314.0    AML  \n",
      "41   648.0    AML  \n",
      "42   416.0    AML  \n",
      "43  1584.0    AML  \n",
      "44  1068.0    AML  \n",
      "45  1182.0    AML  \n",
      "46  1754.0    AML  \n",
      "47  1681.0    AML  \n",
      "48  1059.0    AML  \n",
      "49   998.0    AML  \n",
      "50   684.0    AML  \n",
      "51   -38.0    AML  \n",
      "52   768.0    AML  \n",
      "53  -395.0    AML  \n",
      "54   427.0    AML  \n",
      "55   723.0    AML  \n",
      "56   832.0    AML  \n",
      "0    716.0    ALL  \n",
      "1   1646.0    ALL  \n",
      "2    853.0    ALL  \n",
      "3    458.0    ALL  \n",
      "7   1009.0    AML  \n",
      "8    521.0    AML  \n",
      "9    261.0    AML  \n",
      "10   346.0    AML  \n",
      "11   825.0    AML  \n",
      "12   385.0    AML  \n",
      "13  1228.0    AML  \n",
      "14   791.0    AML  \n",
      "\n",
      "[52 rows x 12583 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'D:\\GitHub\\TA_Classification_Microarray\\dataset\\Leukimia\\MLL_train.data', header=-1)\n",
    "data1 = pd.read_csv(r'D:\\GitHub\\TA_Classification_Microarray\\dataset\\Leukimia\\MLL_test.data', header=-1)\n",
    "\n",
    "data=data.drop(data.index[[20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36]])\n",
    "data1=data1.drop(data.index[[4,5,6]])\n",
    "data=data.append(data1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.iloc[:, :-1] #mengambil semua row dan kolom kecuali kolom terakhir\n",
    "y = data.iloc[:, -1:]#mengambil semua baris namun hanya kolom terakhir\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_std = scaler.fit_transform(X_std,x)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "x = preprocessing.normalize(x)\n",
    "x = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALL' 'ALL' 'ALL' 'ALL' 'ALL' 'ALL' 'ALL' 'ALL' 'ALL' 'ALL' 'ALL' 'ALL'\n",
      " 'ALL' 'ALL' 'ALL' 'ALL' 'ALL' 'ALL' 'ALL' 'ALL' 'AML' 'AML' 'AML' 'AML'\n",
      " 'AML' 'AML' 'AML' 'AML' 'AML' 'AML' 'AML' 'AML' 'AML' 'AML' 'AML' 'AML'\n",
      " 'AML' 'AML' 'AML' 'AML' 'ALL' 'ALL' 'ALL' 'ALL' 'AML' 'AML' 'AML' 'AML'\n",
      " 'AML' 'AML' 'AML' 'AML']\n"
     ]
    }
   ],
   "source": [
    "y=np.ravel(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stdout\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to train and test on 50-50 ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shidqiaqil\\Anaconda3\\lib\\site-packages\\sklearn\\cross_decomposition\\pls_.py:291: UserWarning: Y residual constant at iteration 25\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n",
      "C:\\Users\\Shidqiaqil\\Anaconda3\\lib\\site-packages\\sklearn\\cross_decomposition\\pls_.py:291: UserWarning: Y residual constant at iteration 25\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    }
   ],
   "source": [
    "pls = PLSRegression(n_components=30)\n",
    "pls.fit(X_train, X_test)\n",
    "X_pls = pls.fit_transform(X_train, X_test)\n",
    "x2 =pls.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0          1          2          3          4          5   \\\n",
      "0   -8.812304 -48.161612  19.918784   0.780399  16.227201 -18.339060   \n",
      "1   16.884011 -44.824979  47.135771  14.097067  10.776487  -1.476370   \n",
      "2  -24.315318 -47.799808 -29.186057 -24.588027   3.903748 -21.338167   \n",
      "3   38.596194 -65.279887 -10.292897 -15.004723  24.327578   8.141970   \n",
      "4   -7.403255 -19.705344  23.620341  16.421877   5.129587 -14.243136   \n",
      "5    3.184267 -36.468044  30.663548   6.417302  20.279322  -8.415709   \n",
      "6   -8.651843 -64.432264  19.020443   9.526215   8.953103 -21.935972   \n",
      "7  -16.537927 -49.427811  22.412332  21.217424  -5.200572 -15.586242   \n",
      "8    8.038623 -45.990683  13.071480   1.597833  -5.994180 -19.043365   \n",
      "9   27.287371 -18.105769  61.071312  22.674643  14.231258  40.825529   \n",
      "10   6.308272 -40.611323  45.127808  20.257905  15.491863  -5.770684   \n",
      "11   5.654697 -46.848974   5.681483 -11.151685  11.069361   3.663012   \n",
      "12  -5.007373 -26.096678  -2.044294  15.346560   8.621212  -4.487968   \n",
      "13  16.416419 -25.855591  48.745505  19.346802  11.649737 -10.840183   \n",
      "14  76.242511 -36.530617 -55.509228  49.393956 -18.377314 -23.726660   \n",
      "15  33.249451 -68.910511  31.815937  10.326319   1.033282  17.287945   \n",
      "16  25.603987  -8.043071   0.247477  14.925189  14.174648  12.971987   \n",
      "17  13.841301 -43.744020  17.520301 -15.451151  -7.315178   1.814181   \n",
      "18   9.619015 -48.205842  37.133105   8.213640  15.180847   2.810892   \n",
      "19  -5.376711 -10.125477  21.655531  28.622492   8.935764 -10.315617   \n",
      "20 -29.174642  25.285014   1.224830   5.037324   0.739333   7.382588   \n",
      "21  -4.155049   9.862565 -11.474113 -64.374266  -5.758773 -40.117983   \n",
      "22 -17.351357  23.783650  12.579286   2.925038   8.515519  -4.979927   \n",
      "23  31.144981  41.394526 -21.876677 -12.806562 -11.829732  16.395611   \n",
      "24  -4.878528  -6.416062 -46.149738  -1.401456  -9.518432  -6.546256   \n",
      "25   1.176894   1.457306 -46.092585  21.013991   2.830165  27.746144   \n",
      "26   5.699679  12.050713 -12.474082 -15.557346 -19.328776   5.107207   \n",
      "27  -9.003097 -48.011906   2.040755 -63.383504 -42.377718  35.716789   \n",
      "28 -17.350387   6.395668   5.032215   6.160001 -17.638465   4.076379   \n",
      "29 -40.747936  16.255583  18.149579  74.458440 -25.817881  16.449544   \n",
      "30  41.879981  82.253604  71.258911  -7.537543 -49.878701 -29.769240   \n",
      "31  18.671018  50.675635  34.447283 -33.789965  24.686379  21.988101   \n",
      "32 -13.104030  43.516103   1.056326  15.652677  13.091730  -3.327418   \n",
      "33 -24.378911  29.907526 -34.133164  -8.295636 -12.551187 -15.296311   \n",
      "34  -1.345586  40.309424 -51.587511  35.473773  -3.503231  -2.384393   \n",
      "35 -19.713039  45.691885 -11.812428  24.152937   0.323920 -21.587730   \n",
      "36  17.682540  52.721080 -69.107599  43.856786  23.592386  20.161210   \n",
      "37  -4.766881  -9.486484 -16.602207 -13.599927  13.214835  -0.553278   \n",
      "38 -16.718960  45.820356   3.702323  19.164196  26.988655  15.638504   \n",
      "39  22.488010  55.520950 -57.210911  10.364831  27.839322  11.272564   \n",
      "40 -11.071128 -34.607338  13.477199  -0.155646   5.019261  -0.993565   \n",
      "41   2.881716 -36.370094  21.895255  12.903411   3.484805 -15.522080   \n",
      "42 -17.329473 -34.442222  11.073937  12.167024   0.375848 -29.976407   \n",
      "43  -5.490353 -42.302572   1.019548 -32.371056  -5.690972 -12.161858   \n",
      "44 -15.185445 -27.323843 -21.187465 -22.997913 -31.631344  29.276009   \n",
      "45 -30.571796  21.283155 -17.439533   8.363535  17.513652  14.471420   \n",
      "46  -5.771029  34.477782  14.104562 -26.478455  66.114257 -10.582909   \n",
      "47 -26.017901  24.686639  -4.794358   7.483245  15.331693   0.118474   \n",
      "48 -18.250173  -1.947463 -11.466596 -14.111102 -10.790588   2.840066   \n",
      "49 -19.236478  43.219804  -6.155501   3.980017 -12.422574  -7.859192   \n",
      "50 -11.195469  20.338679   0.088686  -2.831864 -20.128285  -3.670510   \n",
      "51  -2.411300  30.257847 -34.050556   2.159484 -11.090224  -6.486639   \n",
      "\n",
      "           6          7          8          9  ...          20         21  \\\n",
      "0    1.779824   0.555327  -6.162829  -0.372302 ...    1.572828   3.777394   \n",
      "1   17.157716   5.800873  -3.005405  10.379288 ...    5.863474  -0.526500   \n",
      "2  -36.563186   1.482670 -22.388660 -16.511762 ...  -14.353617  -3.129141   \n",
      "3    2.395485  20.975588 -35.383197 -40.383741 ...   -0.598833  12.791328   \n",
      "4    6.883088 -11.208813   6.540348   9.488739 ...   -9.349159   1.538687   \n",
      "5   21.069164 -24.825931   6.269766   8.095279 ...   24.132232  -8.383503   \n",
      "6   -4.564474 -10.077468  12.848567  14.099572 ...   -0.458351   8.206020   \n",
      "7    8.238385  10.079538  10.584792  14.070869 ...   25.555780  -6.960527   \n",
      "8  -11.014207   0.614710   8.090933   2.242557 ...    2.681300   0.205994   \n",
      "9   12.822402 -23.058562 -16.408073   9.664216 ...   -0.898613   4.619761   \n",
      "10   3.838632  -4.451569   3.937389  -4.299275 ...    9.393406   6.401934   \n",
      "11   0.966904   0.075066 -16.799911 -13.686115 ...   -0.578158  -2.949642   \n",
      "12   1.996342  -9.385483   6.200891   0.005207 ...   -5.371013  -1.991632   \n",
      "13  -3.040372   7.520546   5.795273  -2.219643 ...    9.446603   1.930922   \n",
      "14 -15.363600  29.812684  16.037870  17.744844 ...   -2.975565   2.827993   \n",
      "15  -5.243747   9.296359  -3.097404 -15.695097 ...    5.271286  -2.693109   \n",
      "16  10.756373  13.940379 -21.730394  13.508528 ...   -4.667071   6.253357   \n",
      "17  11.426634   2.878354 -11.290753   1.682728 ...    5.216476  -2.933268   \n",
      "18   3.490468 -18.770054  -7.685635 -17.152657 ...  -28.011583 -19.524641   \n",
      "19   3.477500  -7.224261   7.056947  10.553078 ...   -6.964703   2.730562   \n",
      "20 -31.164086  -2.518329 -16.988226   8.924133 ...    3.677450  54.266676   \n",
      "21   8.437295 -12.942772  11.176439 -12.756764 ...    4.585727 -10.995230   \n",
      "22  10.110004   6.225654   8.820507   1.018376 ...    5.755007   1.504330   \n",
      "23   3.371418 -20.692071  19.235391  14.559464 ...  -13.590601 -11.542567   \n",
      "24 -19.432593  -9.288903  -0.353243   1.164721 ...    4.370490  -2.257291   \n",
      "25 -39.182428 -24.057871 -10.769488  14.323041 ...   24.429338 -10.091085   \n",
      "26  40.993040  21.035096  -5.615413   3.597801 ...  -20.068640   9.847732   \n",
      "27  -5.391251  10.524896  12.880410 -24.028599 ...   20.782526  -1.822138   \n",
      "28   6.462557  29.705281  -6.086020  10.762320 ...   10.800530 -28.157235   \n",
      "29  -5.944867  18.073733  35.160920 -45.228147 ...   -2.519755   1.114033   \n",
      "30 -30.660398 -15.660679  -6.714144 -14.395598 ...   -2.869415   1.548143   \n",
      "31  -4.253399  36.843144  -0.346352  24.854828 ...    6.407810   7.358760   \n",
      "32  -1.959113  18.146871 -39.417465   9.518573 ...    6.618975 -26.833823   \n",
      "33   2.839531 -16.060502 -14.415087  11.804907 ...   11.450785   0.572088   \n",
      "34  -6.390527 -18.411197   7.163614  -7.873984 ...    5.077224  -3.581776   \n",
      "35  51.129018   9.472583 -25.838234  -7.554078 ...   -0.008702   9.863037   \n",
      "36 -20.965727  -3.074677  -1.304022  -9.765706 ...   -2.043965  -6.969346   \n",
      "37  -5.441114   7.746184  -2.351026   2.935349 ...   -3.953963  -5.187725   \n",
      "38   1.026269  14.240879   8.027066  -1.391750 ...   -0.191666  -1.829468   \n",
      "39  23.734192 -31.963333  15.043767 -35.272329 ...   13.040772   6.020649   \n",
      "40  -3.345864   9.330727 -10.207861   5.916568 ...    5.580173  -2.301714   \n",
      "41  -6.725747  11.381059  11.238394   0.942333 ...   -2.661457   4.013517   \n",
      "42   7.299826 -16.948758   8.349916  17.343780 ...   -9.202445  16.474584   \n",
      "43   3.664141  -8.942456 -21.339331   1.184894 ...   10.689026  -8.548852   \n",
      "44  21.633344  -6.662567  15.279342  29.348035 ...  -19.922830   9.021294   \n",
      "45 -24.298552  -4.971199  -1.430704   6.182258 ...  -34.154062 -19.963786   \n",
      "46 -14.570774  23.058015  46.619518  -1.610247 ...   -1.848911   2.871576   \n",
      "47 -26.038828   6.136033   3.525450   8.142008 ...   -5.202358  -5.023331   \n",
      "48  13.112330  -8.384752  11.265584   8.347843 ...   -7.700899   1.850943   \n",
      "49  -1.780031 -17.621447  -7.377222  -7.647893 ...    3.632191   7.417680   \n",
      "50  -0.350339  -6.193909   7.624280   6.295414 ...   -4.713048  -1.054241   \n",
      "51  -9.532729 -14.834302   0.902403  -5.992285 ...    5.527687  -0.127322   \n",
      "\n",
      "           22         23         24   25   26   27   28   29  \n",
      "0    1.010379   5.938644   1.270341  0.0  0.0  0.0  0.0  0.0  \n",
      "1   -1.913542   5.726242   5.945687  0.0  0.0  0.0  0.0  0.0  \n",
      "2   18.800815 -18.080345   4.897028  0.0  0.0  0.0  0.0  0.0  \n",
      "3  -19.871188  11.765283   0.410060  0.0  0.0  0.0  0.0  0.0  \n",
      "4    0.445434   7.739393  -6.420748  0.0  0.0  0.0  0.0  0.0  \n",
      "5    5.339783 -18.640091   3.957585  0.0  0.0  0.0  0.0  0.0  \n",
      "6   -4.028707  28.628196  38.167513  0.0  0.0  0.0  0.0  0.0  \n",
      "7  -12.704303 -18.423777  -1.880693  0.0  0.0  0.0  0.0  0.0  \n",
      "8    6.902339  -0.774551   6.857128  0.0  0.0  0.0  0.0  0.0  \n",
      "9   -6.260439   7.235327   1.272777  0.0  0.0  0.0  0.0  0.0  \n",
      "10  -0.998020  -1.529231  15.031832  0.0  0.0  0.0  0.0  0.0  \n",
      "11   1.714816  -2.050183  -1.074608  0.0  0.0  0.0  0.0  0.0  \n",
      "12   0.045488 -10.026489 -13.012276  0.0  0.0  0.0  0.0  0.0  \n",
      "13   1.227997   0.835442  14.206911  0.0  0.0  0.0  0.0  0.0  \n",
      "14   5.638275  -4.446882  -2.395979  0.0  0.0  0.0  0.0  0.0  \n",
      "15  -1.171491   7.423288   9.464176  0.0  0.0  0.0  0.0  0.0  \n",
      "16  -0.442158  -1.738954   3.068997  0.0  0.0  0.0  0.0  0.0  \n",
      "17   2.939164  -0.998609  -1.727378  0.0  0.0  0.0  0.0  0.0  \n",
      "18  25.934490 -18.317396  -9.579411  0.0  0.0  0.0  0.0  0.0  \n",
      "19   2.033733   6.443162   3.210090  0.0  0.0  0.0  0.0  0.0  \n",
      "20  17.893767  -3.627363   1.050824  0.0  0.0  0.0  0.0  0.0  \n",
      "21 -13.119905   5.279780   1.714023  0.0  0.0  0.0  0.0  0.0  \n",
      "22  -0.655426 -10.915877  -8.835057  0.0  0.0  0.0  0.0  0.0  \n",
      "23  -1.126408   2.314714   0.944616  0.0  0.0  0.0  0.0  0.0  \n",
      "24   0.289218  -2.599757  -0.389580  0.0  0.0  0.0  0.0  0.0  \n",
      "25  -9.791277  -0.320122  -5.980876  0.0  0.0  0.0  0.0  0.0  \n",
      "26 -15.908611 -13.992842   1.886202  0.0  0.0  0.0  0.0  0.0  \n",
      "27   0.882701   7.140362  -9.649208  0.0  0.0  0.0  0.0  0.0  \n",
      "28  37.173351  31.084191  -2.681849  0.0  0.0  0.0  0.0  0.0  \n",
      "29 -11.917316  -6.571205   2.543597  0.0  0.0  0.0  0.0  0.0  \n",
      "30  -0.788470   0.079012   4.142091  0.0  0.0  0.0  0.0  0.0  \n",
      "31   0.166327  -3.037756  -3.078575  0.0  0.0  0.0  0.0  0.0  \n",
      "32 -10.716536  -9.357233   1.881106  0.0  0.0  0.0  0.0  0.0  \n",
      "33 -11.671945  -9.717874   2.207881  0.0  0.0  0.0  0.0  0.0  \n",
      "34  -4.956895  -6.702951  -6.195911  0.0  0.0  0.0  0.0  0.0  \n",
      "35   9.145191   7.094308   1.976729  0.0  0.0  0.0  0.0  0.0  \n",
      "36  -6.501421  -8.025944  -5.189395  0.0  0.0  0.0  0.0  0.0  \n",
      "37   0.607455   6.425529  -0.113300  0.0  0.0  0.0  0.0  0.0  \n",
      "38  -0.926406   3.154387   0.084120  0.0  0.0  0.0  0.0  0.0  \n",
      "39  16.109876   6.225338   1.588906  0.0  0.0  0.0  0.0  0.0  \n",
      "40   3.623266  -2.205167  -1.577621  0.0  0.0  0.0  0.0  0.0  \n",
      "41   5.595622  -1.335589  -0.651035  0.0  0.0  0.0  0.0  0.0  \n",
      "42  -8.355088  20.088870 -43.063150  0.0  0.0  0.0  0.0  0.0  \n",
      "43   7.389317  -5.310737   0.451243  0.0  0.0  0.0  0.0  0.0  \n",
      "44   7.227135 -12.491345  10.612666  0.0  0.0  0.0  0.0  0.0  \n",
      "45 -20.542525  16.256492   0.810051  0.0  0.0  0.0  0.0  0.0  \n",
      "46   2.491008  -6.167643  -1.753913  0.0  0.0  0.0  0.0  0.0  \n",
      "47   4.565858  -1.696247  -0.483019  0.0  0.0  0.0  0.0  0.0  \n",
      "48   0.855909  -1.987319   1.471006  0.0  0.0  0.0  0.0  0.0  \n",
      "49   3.893407  -6.900913  -2.287497  0.0  0.0  0.0  0.0  0.0  \n",
      "50   2.241983   0.950139   1.445734  0.0  0.0  0.0  0.0  0.0  \n",
      "51   0.204425  -1.836922  -4.112037  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[52 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "x2=pd.DataFrame(x2)\n",
    "print(x2)\n",
    "#x2= NormalizeData(x2)\n",
    "#print(X_pls)\n",
    "#two_arrays = X_pls\n",
    "#datapls = np.hstack(two_arrays)\n",
    "#np.savetxt('lungcancerpls111.csv', datapls, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import xlsxwriter\n",
    "j=2\n",
    "k=1\n",
    "workbook = xlsxwriter.Workbook('Akurasi Leukimia.xlsx')\n",
    "worksheet = workbook.add_worksheet(\"knn leukimia\")\n",
    "row=0\n",
    "col=0\n",
    "row2=0\n",
    "col2=0\n",
    "row3=0\n",
    "#i=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1\n",
      "cv_scores mean  fold  2 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  3 : 94.22657952069716 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  4 : 96.15384615384616 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 94.36363636363637 %  , nopls 98.18181818181819 %\n",
      "cv_scores mean  fold  6 : 94.21296296296296 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 96.17346938775509 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 94.04761904761905 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 96.29629629629632 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 94.33333333333334 %  , nopls 96.66666666666669 %\n",
      "cv_scores mean  fold  11 : 94.0909090909091 %  , nopls 96.66666666666667 %\n",
      "rata-rata  95.19755752339786 , no pls  97.7086987086987\n",
      "k= 2\n",
      "cv_scores mean  fold  2 : 86.53846153846155 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  3 : 90.52287581699346 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  4 : 92.3076923076923 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 92.72727272727273 %  , nopls 96.36363636363636 %\n",
      "cv_scores mean  fold  6 : 92.5925925925926 %  , nopls 96.29629629629629 %\n",
      "cv_scores mean  fold  7 : 92.60204081632652 %  , nopls 94.64285714285714 %\n",
      "cv_scores mean  fold  8 : 92.55952380952381 %  , nopls 94.64285714285714 %\n",
      "cv_scores mean  fold  9 : 92.59259259259261 %  , nopls 96.56084656084656 %\n",
      "cv_scores mean  fold  10 : 93.0 %  , nopls 95.0 %\n",
      "cv_scores mean  fold  11 : 92.72727272727272 %  , nopls 94.84848484848484 %\n",
      "rata-rata  91.81703249287284 , no pls  96.07338957338958\n",
      "k= 3\n",
      "cv_scores mean  fold  2 : 92.3076923076923 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  3 : 98.14814814814815 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  4 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 98.18181818181819 %  , nopls 98.18181818181819 %\n",
      "cv_scores mean  fold  6 : 98.14814814814815 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 96.42857142857143 %  , nopls 98.21428571428571 %\n",
      "cv_scores mean  fold  8 : 96.42857142857143 %  , nopls 98.21428571428572 %\n",
      "cv_scores mean  fold  9 : 96.56084656084656 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 96.66666666666669 %  , nopls 98.33333333333334 %\n",
      "cv_scores mean  fold  11 : 96.66666666666667 %  , nopls 98.48484848484848 %\n",
      "rata-rata  96.76140526140526 , no pls  98.03683353683354\n",
      "k= 4\n",
      "cv_scores mean  fold  2 : 88.46153846153845 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  3 : 96.18736383442265 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  4 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 98.18181818181819 %  , nopls 98.18181818181819 %\n",
      "cv_scores mean  fold  6 : 98.14814814814815 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 98.21428571428571 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 98.21428571428572 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 98.14814814814815 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 98.33333333333334 %  , nopls 96.66666666666669 %\n",
      "cv_scores mean  fold  11 : 98.18181818181819 %  , nopls 96.66666666666667 %\n",
      "rata-rata  97.01476627947218 , no pls  97.7086987086987\n",
      "k= 5\n",
      "cv_scores mean  fold  2 : 90.38461538461539 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  3 : 96.18736383442265 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  4 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 98.18181818181819 %  , nopls 98.18181818181819 %\n",
      "cv_scores mean  fold  6 : 98.14814814814815 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 98.21428571428571 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 98.21428571428572 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 98.14814814814815 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 98.33333333333334 %  , nopls 98.33333333333334 %\n",
      "cv_scores mean  fold  11 : 98.18181818181819 %  , nopls 98.48484848484848 %\n",
      "rata-rata  97.20707397177986 , no pls  97.86487586487587\n",
      "k= 6\n",
      "cv_scores mean  fold  2 : 82.6923076923077 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  3 : 86.60130718954248 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  4 : 90.3846153846154 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 91.91919191919192 %  , nopls 98.18181818181819 %\n",
      "cv_scores mean  fold  6 : 94.21296296296296 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  7 : 94.13265306122447 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 96.13095238095238 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 94.07407407407408 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 96.33333333333333 %  , nopls 96.66666666666669 %\n",
      "cv_scores mean  fold  11 : 96.36363636363636 %  , nopls 96.66666666666667 %\n",
      "rata-rata  92.28450343618411 , no pls  97.70157620157622\n",
      "k= 7\n",
      "cv_scores mean  fold  2 : 86.53846153846155 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  3 : 88.45315904139433 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  4 : 90.3846153846154 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  5 : 96.36363636363636 %  , nopls 96.36363636363636 %\n",
      "cv_scores mean  fold  6 : 96.29629629629629 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 94.13265306122447 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 96.13095238095238 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 96.29629629629632 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 96.33333333333333 %  , nopls 98.33333333333334 %\n",
      "cv_scores mean  fold  11 : 96.36363636363636 %  , nopls 98.48484848484848 %\n",
      "rata-rata  93.72930400598469 , no pls  97.30556480556481\n",
      "k= 8\n",
      "cv_scores mean  fold  2 : 80.76923076923077 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  3 : 86.60130718954248 %  , nopls 96.18736383442265 %\n",
      "cv_scores mean  fold  4 : 84.61538461538461 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  5 : 86.28282828282828 %  , nopls 96.36363636363636 %\n",
      "cv_scores mean  fold  6 : 90.27777777777777 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 86.47959183673468 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 90.47619047619048 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 90.37037037037037 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 90.99999999999999 %  , nopls 96.66666666666669 %\n",
      "cv_scores mean  fold  11 : 90.45454545454544 %  , nopls 96.66666666666667 %\n",
      "rata-rata  87.73272267726047 , no pls  96.76100152570743\n",
      "k= 9\n",
      "cv_scores mean  fold  2 : 86.53846153846155 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  3 : 86.60130718954248 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  4 : 88.46153846153847 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  5 : 88.10101010101012 %  , nopls 96.36363636363636 %\n",
      "cv_scores mean  fold  6 : 94.21296296296296 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 92.09183673469387 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 94.04761904761905 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 94.07407407407408 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 92.66666666666666 %  , nopls 96.66666666666669 %\n",
      "cv_scores mean  fold  11 : 92.27272727272727 %  , nopls 96.66666666666667 %\n",
      "rata-rata  90.90682040492965 , no pls  97.14938764938766\n",
      "k= 10\n",
      "cv_scores mean  fold  2 : 84.61538461538461 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  3 : 84.74945533769062 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  4 : 82.6923076923077 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 84.46464646464646 %  , nopls 98.18181818181819 %\n",
      "cv_scores mean  fold  6 : 86.3425925925926 %  , nopls 96.29629629629629 %\n",
      "cv_scores mean  fold  7 : 86.47959183673468 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 90.47619047619048 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 90.37037037037037 %  , nopls 96.56084656084656 %\n",
      "cv_scores mean  fold  10 : 90.99999999999999 %  , nopls 96.66666666666669 %\n",
      "cv_scores mean  fold  11 : 90.45454545454544 %  , nopls 96.66666666666667 %\n",
      "rata-rata  87.1645084840463 , no pls  97.33832833832834\n",
      "k= 11\n",
      "cv_scores mean  fold  2 : 90.38461538461539 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  3 : 86.71023965141612 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  4 : 86.53846153846155 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 86.28282828282828 %  , nopls 98.18181818181819 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores mean  fold  6 : 88.42592592592592 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 86.47959183673468 %  , nopls 98.21428571428571 %\n",
      "cv_scores mean  fold  8 : 90.47619047619048 %  , nopls 98.21428571428572 %\n",
      "cv_scores mean  fold  9 : 90.37037037037037 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 92.66666666666666 %  , nopls 98.33333333333334 %\n",
      "cv_scores mean  fold  11 : 92.27272727272727 %  , nopls 98.48484848484848 %\n",
      "rata-rata  89.06076174059366 , no pls  98.22914122914123\n"
     ]
    }
   ],
   "source": [
    "#create a new KNN model\n",
    "while k<12:\n",
    "    i=2;\n",
    "    total=0\n",
    "    total1=0\n",
    "    knn = KNeighborsClassifier(n_neighbors= k)\n",
    "    knn.fit(X_train, y_train) \n",
    "    print('k=',k)\n",
    "    while i<=11:\n",
    "        cv_scores = cross_val_score(knn, x2,y , cv= i)\n",
    "        cv_scores2= cross_val_score(knn, x,y, cv=i)\n",
    "        a = cv_scores\n",
    "        #print(cv_scores)\n",
    "        print(\"cv_scores mean \",\"fold \",i,\": {}\".format(np.mean(cv_scores)*100),\"%\",\" ,\",\"nopls {}\".format(np.mean(cv_scores2)*100),\"%\")\n",
    "        if i<=11:\n",
    "            total+=np.mean(cv_scores)*100\n",
    "            total1+=np.mean(cv_scores2)*100\n",
    "            if i==11:\n",
    "                total=total/10\n",
    "                total1=total1/10\n",
    "        i+=1\n",
    "    print(\"rata-rata \",total,\", no pls \",total1)\n",
    "    k+=1\n",
    "workbook.close() \n",
    "#knn.fit(y_c,)\n",
    "#y_pred= knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters:\n",
      " {'C': 1, 'gamma': 1e-05}\n",
      "Best Estimators:\n",
      " SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1e-05, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shidqiaqil\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "C:\\Users\\Shidqiaqil\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "# Parameter Grid\n",
    "param_grid = {'C': [0.1, 1], 'gamma': [1, 0.1, 0.01, 0.001, 0.00001]}\n",
    " \n",
    "# Make grid search classifier\n",
    "clf_grid = GridSearchCV(SVC(), param_grid, verbose=1)\n",
    " \n",
    "# Train the classifier\n",
    "clf_grid.fit(x2, y)\n",
    " \n",
    "# clf = grid.best_estimator_()\n",
    "print(\"Best Parameters:\\n\", clf_grid.best_params_)\n",
    "print(\"Best Estimators:\\n\", clf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores mean: 53.84615384615385 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean: 53.812636165577345 %  , nopls 100.0 %\n",
      "cv_scores mean: 53.84615384615385 %  , nopls 100.0 %\n",
      "cv_scores mean: 53.83838383838384 %  , nopls 100.0 %\n",
      "cv_scores mean: 53.70370370370371 %  , nopls 100.0 %\n",
      "cv_scores mean: 54.081632653061206 %  , nopls 100.0 %\n",
      "cv_scores mean: 53.57142857142857 %  , nopls 100.0 %\n",
      "cv_scores mean: 54.12698412698413 %  , nopls 100.0 %\n",
      "cv_scores mean: 54.0 %  , nopls 100.0 %\n",
      "cv_scores mean: 53.63636363636364 %  , nopls 100.0 %\n",
      "53.84634403878101\n",
      "99.8076923076923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "j=2\n",
    "k=1\n",
    "total=0\n",
    "total1=0\n",
    "\n",
    "while j<=11:\n",
    "    classifier = SVC(kernel='rbf', C=1000, gamma=1)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    cv_scores = cross_val_score(classifier , x2,y , cv=j)\n",
    "    cv_scores2 = cross_val_score(classifier , x,y , cv=j)\n",
    "    #print(cv_scores)\n",
    "    print(\"cv_scores mean: {}\".format(np.mean(cv_scores)*100),\"%\",\" ,\",\"nopls {}\".format(np.mean(cv_scores2)*100),\"%\")\n",
    "    if j<=11:\n",
    "        total+=np.mean(cv_scores)*100\n",
    "        total1+=np.mean(cv_scores2)*100\n",
    "        if j==11:\n",
    "            total=total/10\n",
    "            total1=total1/10\n",
    "    j+=1\n",
    "print(total)\n",
    "print(total1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores mean: 94.23076923076923 %  , nopls 53.84615384615385 %\n",
      "cv_scores mean: 96.18736383442265 %  , nopls 53.812636165577345 %\n",
      "cv_scores mean: 98.07692307692308 %  , nopls 53.84615384615385 %\n",
      "cv_scores mean: 98.18181818181819 %  , nopls 53.83838383838384 %\n",
      "cv_scores mean: 98.14814814814815 %  , nopls 53.70370370370371 %\n",
      "cv_scores mean: 98.21428571428571 %  , nopls 54.081632653061206 %\n",
      "cv_scores mean: 98.21428571428572 %  , nopls 53.57142857142857 %\n",
      "cv_scores mean: 98.41269841269842 %  , nopls 54.12698412698413 %\n",
      "cv_scores mean: 98.33333333333334 %  , nopls 54.0 %\n",
      "cv_scores mean: 98.48484848484848 %  , nopls 53.63636363636364 %\n",
      "97.6484474131533\n",
      "53.84634403878101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "j=2\n",
    "k=1\n",
    "total=0\n",
    "total1=0\n",
    "\n",
    "while j<=11:\n",
    "    classifier = SVC(kernel='linear', C=0.1)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    cv_scores = cross_val_score(classifier , x2,y , cv=j)\n",
    "    cv_scores2 = cross_val_score(classifier , x,y , cv=j)\n",
    "    #print(cv_scores)\n",
    "    print(\"cv_scores mean: {}\".format(np.mean(cv_scores)*100),\"%\",\" ,\",\"nopls {}\".format(np.mean(cv_scores2)*100),\"%\")\n",
    "    if j<=11:\n",
    "        total+=np.mean(cv_scores)*100\n",
    "        total1+=np.mean(cv_scores2)*100\n",
    "        if j==11:\n",
    "            total=total/10\n",
    "            total1=total1/10\n",
    "    j+=1\n",
    "print(total)\n",
    "print(total1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores mean: 94.23076923076923 %  , nopls 53.84615384615385 %\n",
      "cv_scores mean: 96.18736383442265 %  , nopls 53.812636165577345 %\n",
      "cv_scores mean: 98.07692307692308 %  , nopls 53.84615384615385 %\n",
      "cv_scores mean: 98.18181818181819 %  , nopls 53.83838383838384 %\n",
      "cv_scores mean: 98.14814814814815 %  , nopls 53.70370370370371 %\n",
      "cv_scores mean: 98.21428571428571 %  , nopls 54.081632653061206 %\n",
      "cv_scores mean: 98.21428571428572 %  , nopls 53.57142857142857 %\n",
      "cv_scores mean: 98.41269841269842 %  , nopls 54.12698412698413 %\n",
      "cv_scores mean: 98.33333333333334 %  , nopls 54.0 %\n",
      "cv_scores mean: 98.48484848484848 %  , nopls 53.63636363636364 %\n",
      "97.6484474131533\n",
      "53.84634403878101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "j=2\n",
    "k=1\n",
    "total=0\n",
    "total1=0\n",
    "\n",
    "while j<=11:\n",
    "    classifier = SVC(kernel='poly', degree=1, gamma='auto')\n",
    "    classifier.fit(X_train,y_train)\n",
    "    cv_scores = cross_val_score(classifier , x2,y , cv=j)\n",
    "    cv_scores2 = cross_val_score(classifier , x,y , cv=j)\n",
    "    #print(cv_scores)\n",
    "    print(\"cv_scores mean: {}\".format(np.mean(cv_scores)*100),\"%\",\" ,\",\"nopls {}\".format(np.mean(cv_scores2)*100),\"%\")\n",
    "    if j<=11:\n",
    "        total+=np.mean(cv_scores)*100\n",
    "        total1+=np.mean(cv_scores2)*100\n",
    "        if j==11:\n",
    "            total=total/10\n",
    "            total1=total1/10\n",
    "    j+=1\n",
    "print(total)\n",
    "print(total1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "sns.set()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=1)\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn.fit(x, y)\n",
    "y_pred = knn.predict(x1)\n",
    "acc = accuracy_score(y1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALL' 'ALL' 'ALL' 'ALL' 'AML' 'AML' 'AML' 'AML' 'AML' 'AML' 'AML' 'AML']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1\n",
      "cv_scores mean  fold  2 : 100.0 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  3 : 100.0 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  4 : 100.0 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  5 : 100.0 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  6 : 100.0 %  , nopls 100.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shidqiaqil\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Shidqiaqil\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Shidqiaqil\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Shidqiaqil\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=6.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Shidqiaqil\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=7.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Shidqiaqil\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=7.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores mean  fold  7 : 100.0 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  8 : 100.0 %  , nopls 100.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shidqiaqil\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=8.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Shidqiaqil\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=8.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_splits=9 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-76cc2bda5e58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'k='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mcv_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mcv_scores2\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    752\u001b[0m             tasks = BatchedCalls(itertools.islice(iterator, batch_size),\n\u001b[0;32m    753\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_nested_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m                                  self._pickle_cache)\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m                 \u001b[1;31m# No more tasks available in the iterator: tell caller to stop.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, iterator_slice, backend_and_jobs, pickle_cache)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator_slice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend_and_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator_slice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend_and_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    233\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m    234\u001b[0m     scores = parallel(\n\u001b[1;32m--> 235\u001b[1;33m         delayed(_fit_and_score)(\n\u001b[0m\u001b[0;32m    236\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    329\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_BaseKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m         \u001b[0mtest_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    644\u001b[0m             raise ValueError(\"n_splits=%d cannot be greater than the\"\n\u001b[0;32m    645\u001b[0m                              \u001b[1;34m\" number of members in each class.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m                              % (self.n_splits))\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmin_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m             warnings.warn((\"The least populated class in y has only %d\"\n",
      "\u001b[1;31mValueError\u001b[0m: n_splits=9 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA(n_components=30)\n",
    "pca.fit(x)\n",
    "x3 = pca.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1\n",
      "cv_scores mean  fold  2 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  3 : 100.0 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  4 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 98.18181818181819 %  , nopls 98.18181818181819 %\n",
      "cv_scores mean  fold  6 : 98.14814814814815 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 98.41269841269842 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 96.66666666666669 %  , nopls 96.66666666666669 %\n",
      "cv_scores mean  fold  11 : 96.66666666666667 %  , nopls 96.66666666666667 %\n",
      "rata-rata  97.7086987086987 , no pls  97.7086987086987\n",
      "k= 2\n",
      "cv_scores mean  fold  2 : 96.15384615384616 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  3 : 96.18736383442265 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  4 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 96.36363636363636 %  , nopls 96.36363636363636 %\n",
      "cv_scores mean  fold  6 : 96.29629629629629 %  , nopls 96.29629629629629 %\n",
      "cv_scores mean  fold  7 : 94.64285714285714 %  , nopls 94.64285714285714 %\n",
      "cv_scores mean  fold  8 : 94.64285714285714 %  , nopls 94.64285714285714 %\n",
      "cv_scores mean  fold  9 : 96.56084656084656 %  , nopls 96.56084656084656 %\n",
      "cv_scores mean  fold  10 : 95.0 %  , nopls 95.0 %\n",
      "cv_scores mean  fold  11 : 94.84848484848484 %  , nopls 94.84848484848484 %\n",
      "rata-rata  95.87731114201702 , no pls  96.07338957338958\n",
      "k= 3\n",
      "cv_scores mean  fold  2 : 96.15384615384616 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  3 : 98.14814814814815 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  4 : 96.15384615384616 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 96.36363636363636 %  , nopls 98.18181818181819 %\n",
      "cv_scores mean  fold  6 : 96.29629629629629 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 96.42857142857143 %  , nopls 98.21428571428571 %\n",
      "cv_scores mean  fold  8 : 96.42857142857143 %  , nopls 98.21428571428572 %\n",
      "cv_scores mean  fold  9 : 96.56084656084656 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 96.66666666666669 %  , nopls 98.33333333333334 %\n",
      "cv_scores mean  fold  11 : 96.66666666666667 %  , nopls 98.48484848484848 %\n",
      "rata-rata  96.58670958670959 , no pls  98.03683353683354\n",
      "k= 4\n",
      "cv_scores mean  fold  2 : 96.15384615384616 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  3 : 98.14814814814815 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  4 : 96.15384615384616 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 96.36363636363636 %  , nopls 98.18181818181819 %\n",
      "cv_scores mean  fold  6 : 96.29629629629629 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 96.56084656084656 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 96.66666666666669 %  , nopls 96.66666666666669 %\n",
      "cv_scores mean  fold  11 : 96.66666666666667 %  , nopls 96.66666666666667 %\n",
      "rata-rata  96.58670958670959 , no pls  97.7086987086987\n",
      "k= 5\n",
      "cv_scores mean  fold  2 : 96.15384615384616 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  3 : 98.14814814814815 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  4 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 98.18181818181819 %  , nopls 98.18181818181819 %\n",
      "cv_scores mean  fold  6 : 98.14814814814815 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 98.21428571428571 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 98.21428571428572 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 98.41269841269842 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 98.33333333333334 %  , nopls 98.33333333333334 %\n",
      "cv_scores mean  fold  11 : 98.48484848484848 %  , nopls 98.48484848484848 %\n",
      "rata-rata  98.03683353683354 , no pls  97.86487586487587\n",
      "k= 6\n",
      "cv_scores mean  fold  2 : 98.07692307692308 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  3 : 100.0 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  4 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 98.18181818181819 %  , nopls 98.18181818181819 %\n",
      "cv_scores mean  fold  6 : 98.14814814814815 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  7 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 98.41269841269842 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 98.33333333333334 %  , nopls 96.66666666666669 %\n",
      "cv_scores mean  fold  11 : 98.48484848484848 %  , nopls 96.66666666666667 %\n",
      "rata-rata  98.05718355718356 , no pls  97.70157620157622\n",
      "k= 7\n",
      "cv_scores mean  fold  2 : 96.15384615384616 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  3 : 100.0 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  4 : 98.07692307692308 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  5 : 98.18181818181819 %  , nopls 96.36363636363636 %\n",
      "cv_scores mean  fold  6 : 98.14814814814815 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 98.41269841269842 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 98.33333333333334 %  , nopls 98.33333333333334 %\n",
      "cv_scores mean  fold  11 : 98.48484848484848 %  , nopls 98.48484848484848 %\n",
      "rata-rata  97.86487586487587 , no pls  97.30556480556481\n",
      "k= 8\n",
      "cv_scores mean  fold  2 : 96.15384615384616 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  3 : 98.03921568627452 %  , nopls 96.18736383442265 %\n",
      "cv_scores mean  fold  4 : 98.07692307692308 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  5 : 98.18181818181819 %  , nopls 96.36363636363636 %\n",
      "cv_scores mean  fold  6 : 100.0 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 98.41269841269842 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 96.66666666666669 %  , nopls 96.66666666666669 %\n",
      "cv_scores mean  fold  11 : 96.66666666666667 %  , nopls 96.66666666666667 %\n",
      "rata-rata  97.50549777020366 , no pls  96.76100152570743\n",
      "k= 9\n",
      "cv_scores mean  fold  2 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  3 : 100.0 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  4 : 98.07692307692308 %  , nopls 96.15384615384616 %\n",
      "cv_scores mean  fold  5 : 98.18181818181819 %  , nopls 96.36363636363636 %\n",
      "cv_scores mean  fold  6 : 98.14814814814815 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 98.41269841269842 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 96.66666666666669 %  , nopls 96.66666666666669 %\n",
      "cv_scores mean  fold  11 : 96.66666666666667 %  , nopls 96.66666666666667 %\n",
      "rata-rata  97.7086987086987 , no pls  97.14938764938766\n",
      "k= 10\n",
      "cv_scores mean  fold  2 : 96.15384615384616 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  3 : 100.0 %  , nopls 100.0 %\n",
      "cv_scores mean  fold  4 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 98.18181818181819 %  , nopls 98.18181818181819 %\n",
      "cv_scores mean  fold  6 : 98.14814814814815 %  , nopls 96.29629629629629 %\n",
      "cv_scores mean  fold  7 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  8 : 96.42857142857143 %  , nopls 96.42857142857143 %\n",
      "cv_scores mean  fold  9 : 96.56084656084656 %  , nopls 96.56084656084656 %\n",
      "cv_scores mean  fold  10 : 96.66666666666669 %  , nopls 96.66666666666669 %\n",
      "cv_scores mean  fold  11 : 96.66666666666667 %  , nopls 96.66666666666667 %\n",
      "rata-rata  97.33120583120584 , no pls  97.33832833832834\n",
      "k= 11\n",
      "cv_scores mean  fold  2 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  3 : 98.14814814814815 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  4 : 98.07692307692308 %  , nopls 98.07692307692308 %\n",
      "cv_scores mean  fold  5 : 98.18181818181819 %  , nopls 98.18181818181819 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores mean  fold  6 : 98.14814814814815 %  , nopls 98.14814814814815 %\n",
      "cv_scores mean  fold  7 : 98.21428571428571 %  , nopls 98.21428571428571 %\n",
      "cv_scores mean  fold  8 : 98.21428571428572 %  , nopls 98.21428571428572 %\n",
      "cv_scores mean  fold  9 : 98.41269841269842 %  , nopls 98.41269841269842 %\n",
      "cv_scores mean  fold  10 : 98.33333333333334 %  , nopls 98.33333333333334 %\n",
      "cv_scores mean  fold  11 : 98.48484848484848 %  , nopls 98.48484848484848 %\n",
      "rata-rata  98.22914122914123 , no pls  98.22914122914123\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import xlsxwriter\n",
    "j=2\n",
    "k=1\n",
    "\n",
    "while k<12:\n",
    "    i=2;\n",
    "    total=0\n",
    "    total1=0\n",
    "    knn = KNeighborsClassifier(n_neighbors= k)\n",
    "    knn.fit(X_train,y_train) \n",
    "    print('k=',k)\n",
    "    while i<=11:\n",
    "        cv_scores = cross_val_score(knn, x3,y , cv= i)\n",
    "        cv_scores2= cross_val_score(knn, x,y, cv=i)\n",
    "        a = cv_scores\n",
    "        #print(cv_scores)\n",
    "        print(\"cv_scores mean \",\"fold \",i,\": {}\".format(np.mean(cv_scores)*100),\"%\",\" ,\",\"nopls {}\".format(np.mean(cv_scores2)*100),\"%\")\n",
    "        if i<=11:\n",
    "            total+=np.mean(cv_scores)*100\n",
    "            total1+=np.mean(cv_scores2)*100\n",
    "            if i==11:\n",
    "                total=total/10\n",
    "                total1=total1/10\n",
    "        i+=1\n",
    "    print(\"rata-rata \",total,\", no pls \",total1)\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
